<!DOCTYPE html>
<html>


<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://rg-lcd.github.io/">
            Reward Guided Latent Consistency Distillation
          </a>
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>

<head>
  <meta charset="utf-8">
  <meta name="description"
    content="We proposed T2V-Turbo, which achieves both fast and high-quality video generation by breaking the quality bottleneck of Video Consistency Model.">
  <meta name="keywords" content=" Text-to-Video, Consistency Model, Learning from Human/AI Feedback">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>T2V-Turbo: Breaking the Quality Bottleneck of Video Consistency Model with Mixed Reward Feedback
  </title>
  <!-- custom fonts -->
  <link rel="stylesheet" type="text/css"
    href="https://cdn.rawgit.com/dreampulse/computer-modern-web-font/master/fonts.css">
  <link href="https://fonts.cdnfonts.com/css/proxima-nova-2" rel="stylesheet">
  <!-- end custom fonts -->

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" type="svg" href="./static/rocket.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title"><span
                style="font-family: 'Courier New', monospace;">T2V-Turbo</span>: Breaking the Quality Bottleneck of
              Video Consistency
              Model with Mixed Reward Feedback
            </h1>

            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://sites.google.com/view/jiachenli/home">Jiachen Li</a><sup>1</sup>
              </span>
              <span class="author-block">
                <a href="https://weixi-feng.github.io/">Weixi Feng</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://tsujuifu.github.io/">Tsu-Jui Fu</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://wangxinyilinda.github.io/">Xinyi Wang</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://sites.google.com/site/sugatobasu/">Sugato Basu</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="https://wenhuchen.github.io//">Wenhu Chen</a><sup>3</sup>,
              </span>
              <span class="author-block">
                <a href="https://sites.cs.ucsb.edu/~william/">William Yang Wang</a><sup>1</sup>
              </span>
            </div>


            <div class="is-size-5 publication-authors" style="margin-top: 15px;">
              <span class="author-block"><sup>1</sup>UC Santa Barbara,</span>
              <span class="author-block"><sup>2</sup>Google,</span>
              <span class="author-block"><sup>3</sup>University of Waterloo</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a target="_blank" href="https://arxiv.org/pdf/2405.18750.pdf"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a target="_blank" href="https://arxiv.org/abs/2405.18750"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>ArXiv</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a target="_blank" href="https://github.com/Ji4chenLi/t2v-turbo"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <span class="link-block">
                  <a href="https://huggingface.co/jiachenli-ucsb/T2V-Turbo-VC2" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      ðŸ¤—
                    </span>
                    <span>Model Weights</span>
                  </a>
                </span>

                <span class="link-block">
                  <a href="https://huggingface.co/spaces/TIGER-Lab/T2V-Turbo" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      ðŸ¤—
                    </span>
                    <span>Huggingface Space</span>
                  </a>
                </span>

                <!-- Dataset Link. -->
                <!-- <span class="link-block">
                  <a target="_blank" href="https://github.com/google/nerfies/releases/tag/0.1"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="far fa-images"></i>
                    </span>
                    <span>Data</span>
                  </a>
                </span> -->
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
    </div>
  </section>

  <section class="hero is-light is-small">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <h2 class="title is-3">4-step <span style="font-family: 'Courier New', monospace;">T2V-Turbo</span> (VC2)
          Results</h2>
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item item-0054">
            <video poster="" id="0054" autoplay controls muted loop height="100%" playbackRate=2.0>
              <source src="static/videos/4steps/0054.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-0262">
            <video poster="" id="0262" autoplay controls muted loop height="100%" playbackRate=2.0>
              <source src="static/videos/4steps/0262.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-0023">
            <video poster="" id="0023" autoplay controls muted loop height="100%" playbackRate=2.0>
              <source src="static/videos/4steps/0023.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-0021">
            <video poster="" id="0021" autoplay controls muted loop height="100%" playbackRate=2.0>
              <source src="static/videos/4steps/0021.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-0064">
            <video poster="" id="0064" autoplay controls muted loop height="100%" playbackRate=2.0>
              <source src="static/videos/4steps/0064.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-0042">
            <video poster="" id="0042" autoplay controls muted loop height="100%" playbackRate=2.0>
              <source src="static/videos/4steps/0042.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-0437">
            <video poster="" id="0437" autoplay controls muted loop height="100%" playbackRate=2.0>
              <source src="static/videos/4steps/0437.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-0273">
            <video poster="" id="0273" autoplay controls muted loop height="100%" playbackRate=2.0>
              <source src="static/videos/4steps/0273.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-0263">
            <video poster="" id="0273" autoplay controls muted loop height="100%" playbackRate=2.0>
              <source src="static/videos/4steps/0263.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>

    <div class="hero-body">
      <div class="container is-max-desktop">
        <h2 class="title is-3">8-step <span style="font-family: 'Courier New', monospace;">T2V-Turbo</span> (VC2)
          Results</h2>
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item item-0026">
            <video poster="" id="0026" autoplay controls muted loop height="100%" playbackRate=2.0>
              <source src="static/videos/8steps/0026.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-0065">
            <video poster="" id="0065" autoplay controls muted loop height="100%" playbackRate=2.0>
              <source src="static/videos/8steps/0065.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-0278">
            <video poster="" id="0278" autoplay controls muted loop height="100%" playbackRate=2.0>
              <source src="static/videos/8steps/0278.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-0348">
            <video poster="" id="0348" autoplay controls muted loop height="100%" playbackRate=2.0>
              <source src="static/videos/8steps/0348.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-0412">
            <video poster="" id="0412" autoplay controls muted loop height="100%" playbackRate=2.0>
              <source src="static/videos/8steps/0412.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-0436">
            <video poster="" id="0436" autoplay controls muted loop height="100%" playbackRate=2.0>
              <source src="static/videos/8steps/0436.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-0266">
            <video poster="" id="0266" autoplay controls muted loop height="100%" playbackRate=2.0>
              <source src="static/videos/8steps/0266.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-0135">
            <video poster="" id="0135" autoplay controls muted loop height="100%" playbackRate=2.0>
              <source src="static/videos/8steps/0135.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-0062">
            <video poster="" id="0273" autoplay controls muted loop height="100%" playbackRate=2.0>
              <source src="static/videos/8steps/0062.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Demo -->
  <section class="hero is-light" style="margin-top:-100px; margin-bottom:-50px;">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <!-- <div class="section-title">
          <h2 class="title is-3 is-centered">Huggingface Space Demo</h2>
        </div> -->
        <div class="columns is-centered has-text-centered">
          <div class="column">
            <iframe src="https://tiger-lab-t2v-turbo.hf.space" frameborder="0" width="1400" height="700"></iframe>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Diffusion-based text-to-video (T2V) models have achieved significant success but continue to be hampered
              by the
              slow sampling speed of their iterative sampling processes. To address the challenge, consistency models
              have been
              proposed to facilitate fast inference, albeit at the cost of sample quality. In this work, we aim to
              break
              the
              quality bottleneck of a video consistency model (VCM) to achieve <span style="font-weight: bold">both
                fast
                and high-quality video generation</span>.
              We introduce <span style="font-family: 'Courier New', monospace; font-weight: bold">T2V-Turbo</span>,
              which integrates feedback from a mixture of differentiable reward models into the
              consistency distillation (CD) process of a pre-trained T2V model. Notably, we directly optimize rewards
              associated with
              single-step generations that arise naturally from computing the CD loss, effectively bypassing the
              memory
              constraints
              imposed by backpropagating gradients through an iterative sampling process. Remarkably, the 4-step
              generations from our
              <span style="font-family: 'Courier New', monospace; font-weight: bold">T2V-Turbo</span> achieve the
              highest total score on <a href="https://vchitect.github.io/VBench-project/">VBench</a>, even surpassing
              <a href="https://research.runwayml.com/gen2/">Gen-2</a> and
              <a href="https://pika.art/">Pika</a>. We further conduct human evaluations to corroborate the results,
              validating that the 4-step
              generations from our <span
                style="font-family: 'Courier New', monospace; font-weight: bold">T2V-Turbo</span> are preferred over
              the
              50-step DDIM samples from their teacher models, representing more
              than a tenfold acceleration while improving video generation quality.
            </p>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">

      <!-- Training Pipeline. -->
      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Overview of Training Pipeline</h2>

          <img src="./static/images/pipeline.png" alt="" srcset="">
          <div class="content has-text-justified">
            <p>
              Overview of the training pipeline of our <span
                style="font-family: 'Courier New', monospace; font-weight: bold">T2V-Turbo</span>. We integrate reward
              feedback from both an image-text RM and a video-text RM into the VCD procedures by backpropagating
              gradient through the single-step generation process of our <span
                style="font-family: 'Courier New', monospace; font-weight: bold">T2V-Turbo</span>
            </p>
          </div>
        </div>
      </div>
      <!--/ Training Pipeline. -->

      <!-- Automatic Evaluation on VBench. -->
      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Automatic Evaluation on <a href="https://vchitect.github.io/VBench-project/">VBench</a>
          </h2>
          <p>
            We compare our <span style="font-family: 'Courier New', monospace; font-weight: bold">T2V-Turbo</span>
            (VC2)
            and <span style="font-family: 'Courier New', monospace; font-weight: bold">T2V-Turbo</span> (MS) with
            baseline methods across the 16 VBench dimensions. A higher
            score indicates better performance for a particular dimension. We bold the best results for each
            dimension and underline the second-best result. Quality Score is calculated with the 7 dimensions
            from the top table. Semantic Score is calculated with the 9 dimensions from the bottom table.
            Total Score a weighted sum of Quality Score and Semantic Score. Both our <span
              style="font-family: 'Courier New', monospace; font-weight: bold">T2V-Turbo</span> (VC2) and <span
              style="font-family: 'Courier New', monospace; font-weight: bold">T2V-Turbo</span> (MS) <span
              style="font-weight: bold">surpass all baseline methods with
              4 inference steps</span> in terms of Total Score, including the proprietary systems Gen-2 and Pika
          </p>

          <img src="./static/images/vbench_full.png" alt="" srcset="">
          <div class="content has-text-justified">
          </div>
        </div>
      </div>
      <!-- Automatic Evaluation on VBench. -->

      <!-- Automatic Evaluation on VBench. -->
      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Human Evaluation Results with 700 <a
              href="https://evalcrafter.github.io//">EvalCrafter</a> Prompts</h2>
          <p>
            We compare the 4-step and 8-step generations from our <span
              style="font-family: 'Courier New', monospace; font-weight: bold">T2V-Turbo</span> with their teacher T2V
            model and their baseline VCM. Top: results for <span
              style="font-family: 'Courier New', monospace; font-weight: bold">T2V-Turbo</span> (VC2). Bottom: results
            for <span style="font-family: 'Courier New', monospace; font-weight: bold">T2V-Turbo</span> (MS).
          </p>

          <img src="./static/images/human_eval.png" alt="" srcset="">

          <p>
            Notably, the 4-step generations from our <span
              style="font-family: 'Courier New', monospace; font-weight: bold">T2V-Turbo</span> are favored by humans
            over the 50-step generation from their teacher T2V model, representing a 12.5 times inference acceleration
            with improving performance.
          </p>

          <p>
            By increasing the inference steps to 8, we can further improve the visual quality and text-video alignment
            of videos generated from our <span
              style="font-family: 'Courier New', monospace; font-weight: bold">T2V-Turbo</span>.
          </p>
          <p>
            Additionally, our <span style="font-family: 'Courier New', monospace; font-weight: bold">T2V-Turbo</span>
            significantly outperforms its baseline VCM, demonstrating
            the effectiveness of methods that incorporate a mixture of reward feedback into the model training.
          </p>

          <div class="content has-text-justified">
          </div>
        </div>
      </div>
      <!-- Automatic Evaluation on VBench. -->

      <div class="container is-max-desktop">

        <!-- Acknowledgement. -->
        <div class="columns is-centered">
          <div class="column is-full-width">
            <h2 class="title is-3">Acknowledgement</h2>

            <div class="content has-text-justified">
              <p>
                This project would not be possible without the following wonderful prior work.
              </p>

              <p>
                <a href="https://github.com/luosiallen/latent-consistency-model">Latent Consistency Model</a> gave
                inspiration to our method,
                <a href="https://github.com/tgxs002/HPSv2">HPSv2.1</a>, <a
                  href="https://huggingface.co/OpenGVLab/ViCLIP">ViCLIP</a> and <a
                  href="https://huggingface.co/OpenGVLab/InternVideo2-Stage2_1B-224p-f4">InternVid2</a>
                provide great reward models, and
                <a href="https://github.com/huggingface/diffusers/">DiffusersðŸ§¨</a> offered a strong diffusion model
                training framework for building our code from.
              </p>
            </div>
          </div>
        </div>
        <!--/ Acknowledgement. -->
  </section>

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@misc{li2024t2vturbo,
  title={T2V-Turbo: Breaking the Quality Bottleneck of Video Consistency Model with Mixed Reward Feedback},
  author={Jiachen Li and Weixi Feng and Tsu-Jui Fu and Xinyi Wang and Sugato Basu and Wenhu Chen and William Yang Wang},
  journal={ARXIV},
  year={2024}
}
      </code></pre>
    </div>
  </section>


  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <a class="icon-link" href="https://proceedings.mlr.press/v202/li23av/li23av.pdf">
          <i class="fas fa-file-pdf"></i>
        </a>
        <a class="icon-link" href="https://github.com/cfpo-icml23/cfpi" class="external-link" disabled>
          <i class="fab fa-github"></i>
        </a>
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p style="text-align: center
              ">
              Website templated borrowed from <a href="https://github.com/nerfies/nerfies.github.io">nerfies.</a>
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>


</body>

</html>